{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "765fd378-e4f4-4e7d-b4e0-da1b57788c5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 17:07:21.429181: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-15 17:07:21.709445: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-15 17:07:22.910200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-15 17:07:25.342920: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-15 17:07:25.556582: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-15 17:07:25.556635: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "import tensorflow as tf\n",
    "from langdetect import detect\n",
    "from transformers import BertTokenizer\n",
    "from transformers import TFBertModel\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8f8c16-9da5-4cdc-b5c7-b8286831d6a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f84e527a-fb1d-463d-b706-558029f1b345",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Hindu_articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb23d7e3-731c-44d0-9e45-2a3483a28428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47e188c5-5a80-4d56-9c8a-92b8fac9875c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passenger vehicles wholesales rise 26.73% to r...</td>\n",
       "      <td>Domestic passenger vehicle wholesales grew 26....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamborghini unveils Urus S at starting price o...</td>\n",
       "      <td>Automobili Lamborghini has unveiled Urus S, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rupee trade arrangement to help cut transactio...</td>\n",
       "      <td>International trade in the domestic currency w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G-20 Finance Ministers discuss debt distress, ...</td>\n",
       "      <td>G-20 countries discussed the debt distress of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goods exports grew 6% , imports 16.5% this fiscal</td>\n",
       "      <td>India’s goods exports declined for the second ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   \n",
       "0  Passenger vehicles wholesales rise 26.73% to r...  \\\n",
       "1  Lamborghini unveils Urus S at starting price o...   \n",
       "2  Rupee trade arrangement to help cut transactio...   \n",
       "3  G-20 Finance Ministers discuss debt distress, ...   \n",
       "4  Goods exports grew 6% , imports 16.5% this fiscal   \n",
       "\n",
       "                                             Article  \n",
       "0  Domestic passenger vehicle wholesales grew 26....  \n",
       "1  Automobili Lamborghini has unveiled Urus S, th...  \n",
       "2  International trade in the domestic currency w...  \n",
       "3  G-20 countries discussed the debt distress of ...  \n",
       "4  India’s goods exports declined for the second ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dde160e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2316 entries, 0 to 2323\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Title    2316 non-null   object\n",
      " 1   Article  2316 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 54.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55a3eff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2316, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fe8f99b-0a7a-4a23-920f-732e862b02bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "articles = df['Article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef1ceb48-b8b1-4d1d-abe4-11b770f6c0d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Domestic passenger vehicle wholesales grew 26....\n",
       "1       Automobili Lamborghini has unveiled Urus S, th...\n",
       "2       International trade in the domestic currency w...\n",
       "3       G-20 countries discussed the debt distress of ...\n",
       "4       India’s goods exports declined for the second ...\n",
       "                              ...                        \n",
       "2319    B. Suresh’s ward Kings Walk (P. Sai Kumar up) ...\n",
       "2320     Romualdo, who maintains form, may repeat in t...\n",
       "2321    Maharashtra Assembly Speaker Rahul Narwekar sa...\n",
       "2322    The Bharatiya Janata Party (BJP) in Uttar Prad...\n",
       "2323    The Biju Janata Dal on May 13 registered a lan...\n",
       "Name: Article, Length: 2316, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75d3cc8b-8371-4746-9bad-25435e0a80b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Indian Railways turns 170 on April 16. Forever India’s favourite carrier, the railways are as much at a crossroads today as the rest of India — reconciling the trials and tribulations of the past with a future reckoning.\\nPerhaps the most striking symbols of Indian Railways in the current zeitgeist are the talismanic Vande Bharat Express trains. Much of this modernisation contributes to passenger comfort, but sometimes it also leads to a spectacularly short-sighted loss of beauty and cultural heritage.\\nIn cities across India, colonial-era station buildings, many of which are a syncretic mix of local culture and European styles — such as Kacheguda in Hyderabad and Egmore in Chennai — are set for modernisation that will almost certainly produce drab, mall-like monoliths.\\n\\nKacheguda station in Hyderabad is one among the\\xa01,275 railway stations slated for redevelopment under the Amrit Bharat scheme.\\n| Photo Credit:\\nKartik T.\\n\\n\\nEgmore station in Chennai will be redeveloped at a cost of ₹734 crore.\\n| Photo Credit:\\nKartik T.\\n\\nOn April 8, the Prime Minister laid the foundation stone for the redevelopment of Secunderabad Railway Station at a cost of about ₹720 crore. Around the country, 1,275 railway stations are slated for redevelopment under the Amrit Bharat scheme.\\nThe modernisation of railway facilities is a necessary imperative but one that has created debate for decades. When the original Beaux-Arts-style building of New York’s famous Pennsylvania (Penn) Station was demolished in 1963, there was much regret and consternation. Art historian Vincent Scully lamented: “One entered the city like a god; one scuttles in now like a rat.” My abiding fear is that the rush of modernisation coming for our classic railway heritage structures is similar: short-sighted uniform design choices that are justified at every turn as “function over form”, which leave us bereft of a unique legacy.\\n\\nA group of rail vloggers pose next to the Gandhinagar-Mumbai Vande Bharat Express at Mumbai Central, September 30, 2022.\\n| Photo Credit:\\nGetty Images\\n\\nDetermined to document for posterity the glory of our railways, and also highlight their modern-day progress, a new crop of travellers and influencers has jumped on the social travel bandwagon. With the rise in popularity of social media platforms and unfettered Internet bandwidth, these young video bloggers (vloggers) and rail influencers are using trains to take vicarious travel to the huddled masses.\\nViewership and engagement with such efforts increased exponentially during the pandemic as audiences starved of travel and outdoor experiences tuned in en masse to YouTube and Instagram to fulfill their wanderlust.\\n\\nVishwajeet Singh Monu of VS Monu Vlogs makes Hindi language content travelling in trains to various destinations in India.\\n| Photo Credit:\\nVS Monu Vlogs\\n\\nThese vloggers and influencers now cater to disparate and esoteric tastes. Vishwajeet Singh Monu ( VS Monu Vlogs) is the influencer from the heartland who makes Hindi language content travelling in the unreserved compartment of passenger trains one week, and in the AC class of premium trains the next. Here, aspiration is the USP. There are also channels for the more technically inclined, which describe the workings and mechanism of rail technology in layman’s terms.\\nSome like vlogger Chinmay Kole hawk entire train journeys with no additional commentary: just the sights and sounds of travelling on a train, beamed for your edification into your living room and your mobile phone. And there is an increasing cohort of women rail vloggers and influencers, a welcome trend pointing to the all-round appeal of the railways.\\nThe social travel phenomenon is reflective of a much larger reality: Indian trains have been, and always will be, inextricably linked with the lived realities of people. But who should the massive organisation really cater to? Perhaps they are for the business and luxury traveller, who with the proliferation of affordable air travel is taking more often and more naturally to the skies?\\nIn this scenario, it is possible that premium trains are increasingly relegated to operating between nearby cities, winning out over the hassle of airport commutes and security protocols while providing seamless door-to-door connections thanks to modern urban transit systems.\\nOr perhaps the rail network should serve the itinerant migrant populations that move between parts of the country seasonally. The railways were witness, via the Shramik Special trains, to millions of migrant workers making their way back home by any means possible during the COVID-19 lockdown in 2020. The conditions outside stations and inside the trains were appalling and unsafe, but there was no alternative for this group that suddenly found itself without jobs or an income at the height of the pandemic.\\n\\nDuring the 2020 lockdown, Shramik Special trains were used by migrant workers to travel home.\\n| Photo Credit:\\nRanjeet Kumar\\n\\nComposer Vishal Dadlani noted on Twitter: “Migrant workers, most of whom have not earned a penny during lockdown, are being asked to pay for railway tickets to get to their homes.” In the coming years, these questions will remain: can the Indian Railways make such journeys less arduous and dangerous? Will railways ministers undertake inspection tours of overcrowded unreserved compartments, in addition to their well-publicised tours of Vande Bharat trains?\\nOr, conceitedly, are Indian trains for the enthusiasts and rail fans like me, who seek an appropriate preservation of the past while awaiting the future with a combination of excitement and trepidation? We cannot be sure of all the answers, but one thing is certain: the grand story of the Indian Railways — one that has spanned nearly two centuries now — will continue, inextricably linked with the fate and fortunes of India.\\nThe writer is a research scientist whose first love is trains and the Indian Railways.\\n\\nCOMMents\\n\\n SHARE\\n\\n\\nThe Hindu Sunday Magazine\\n\\n/\\n\\ntransport\\n\\n/\\n\\npublic transport\\n\\n/\\n\\nindian railways\\n\\n/\\n\\nrailway\\n\\n/\\n\\nChennai\\n\\n/\\n\\nHyderabad\\n\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = articles[10]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10c8a93a-08b1-42fd-a6b6-d9a6ec3211da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indian Railways turns 170 on April 16.\n",
      "Forever India’s favourite carrier, the railways are as much at a crossroads today as the rest of India — reconciling the trials and tribulations of the past with a future reckoning.\n",
      "\n",
      "Perhaps the most striking symbols of Indian Railways in the current zeitgeist are the talismanic Vande Bharat Express trains.\n",
      "Much of this modernisation contributes to passenger comfort, but sometimes it also leads to a spectacularly short-sighted loss of beauty and cultural heritage.\n",
      "\n",
      "In cities across India, colonial-era station buildings, many of which are a syncretic mix of local culture and European styles — such as Kacheguda in Hyderabad and Egmore in Chennai — are set for modernisation that will almost certainly produce drab, mall-like monoliths.\n",
      "\n",
      "\n",
      "Kacheguda station in Hyderabad is one among the 1,275 railway stations slated for redevelopment under the Amrit Bharat scheme.\n",
      "\n",
      "| Photo Credit:\n",
      "Kartik T.\n",
      "\n",
      "\n",
      "Egmore station in Chennai will be redeveloped at a cost of ₹734 crore.\n",
      "\n",
      "| Photo Credit:\n",
      "Kartik T.\n",
      "\n",
      "\n",
      "On April 8, the Prime Minister laid the foundation stone for the redevelopment of Secunderabad Railway Station at a cost of about ₹720 crore.\n",
      "Around the country, 1,275 railway stations are slated for redevelopment under the Amrit Bharat scheme.\n",
      "\n",
      "The modernisation of railway facilities is a necessary imperative but one that has created debate for decades.\n",
      "When the original Beaux-Arts-style building of New York’s famous Pennsylvania (Penn) Station was demolished in 1963, there was much regret and consternation.\n",
      "Art historian Vincent Scully lamented: “One entered the city like a god; one scuttles in now like a rat.”\n",
      "My abiding fear is that the rush of modernisation coming for our classic railway heritage structures is similar: short-sighted uniform design choices that are justified at every turn as “function over form”, which leave us bereft of a unique legacy.\n",
      "\n",
      "\n",
      "A group of rail vloggers pose next to the Gandhinagar-Mumbai Vande Bharat Express at Mumbai Central, September 30, 2022.\n",
      "\n",
      "| Photo Credit:\n",
      "Getty Images\n",
      "\n",
      "Determined to document for posterity the glory of our railways, and also highlight their modern-day progress, a new crop of travellers and influencers has jumped on the social travel bandwagon.\n",
      "With the rise in popularity of social media platforms and unfettered Internet bandwidth, these young video bloggers (vloggers) and rail influencers are using trains to take vicarious travel to the huddled masses.\n",
      "\n",
      "Viewership and engagement with such efforts increased exponentially during the pandemic as audiences starved of travel and outdoor experiences tuned in en masse to YouTube and Instagram to fulfill their wanderlust.\n",
      "\n",
      "\n",
      "Vishwajeet Singh Monu of VS Monu Vlogs makes Hindi language content travelling in trains to various destinations in India.\n",
      "\n",
      "| Photo Credit:\n",
      "VS Monu Vlogs\n",
      "\n",
      "These vloggers and influencers now cater to disparate and esoteric tastes.\n",
      "Vishwajeet Singh Monu ( VS Monu Vlogs) is the influencer from the heartland who makes Hindi language content travelling in the unreserved compartment of passenger trains one week, and in the AC class of premium trains the next.\n",
      "Here, aspiration is the USP.\n",
      "There are also channels for the more technically inclined, which describe the workings and mechanism of rail technology in layman’s terms.\n",
      "\n",
      "Some like vlogger Chinmay Kole hawk entire train journeys with no additional commentary: just the sights and sounds of travelling on a train, beamed for your edification into your living room and your mobile phone.\n",
      "And there is an increasing cohort of women rail vloggers and influencers, a welcome trend pointing to the all-round appeal of the railways.\n",
      "\n",
      "The social travel phenomenon is reflective of a much larger reality: Indian trains have been, and always will be, inextricably linked with the lived realities of people.\n",
      "But who should the massive organisation really cater to?\n",
      "Perhaps they are for the business and luxury traveller, who with the proliferation of affordable air travel is taking more often and more naturally to the skies?\n",
      "\n",
      "In this scenario, it is possible that premium trains are increasingly relegated to operating between nearby cities, winning out over the hassle of airport commutes and security protocols while providing seamless door-to-door connections thanks to modern urban transit systems.\n",
      "\n",
      "Or perhaps the rail network should serve the itinerant migrant populations that move between parts of the country seasonally.\n",
      "The railways were witness, via the Shramik Special trains, to millions of migrant workers making their way back home by any means possible during the COVID-19 lockdown in 2020.\n",
      "The conditions outside stations and inside the trains were appalling and unsafe, but there was no alternative for this group that suddenly found itself without jobs or an income at the height of the pandemic.\n",
      "\n",
      "\n",
      "During the 2020 lockdown, Shramik Special trains were used by migrant workers to travel home.\n",
      "\n",
      "| Photo Credit:\n",
      "Ranjeet Kumar\n",
      "\n",
      "Composer Vishal Dadlani noted on Twitter: “Migrant workers, most of whom have not earned a penny during lockdown, are being asked to pay for railway tickets to get to their homes.”\n",
      "In the coming years, these questions will remain: can the Indian Railways make such journeys less arduous and dangerous?\n",
      "Will railways ministers undertake inspection tours of overcrowded unreserved compartments, in addition to their well-publicised tours of Vande Bharat trains?\n",
      "Or, conceitedly, are Indian trains for the enthusiasts and rail fans like me, who seek an appropriate preservation of the past while awaiting the future with a combination of excitement and trepidation?\n",
      "We cannot be sure of all the answers, but one thing is certain: the grand story of the Indian Railways — one that has spanned nearly two centuries now — will continue, inextricably linked with the fate and fortunes of India.\n",
      "\n",
      "The writer is a research scientist whose first love is trains and the Indian Railways.\n",
      "\n",
      "\n",
      "COMMents\n",
      "\n",
      " SHARE\n",
      "\n",
      "\n",
      "\n",
      "The Hindu Sunday Magazine\n",
      "\n",
      "/\n",
      "\n",
      "transport\n",
      "\n",
      "/\n",
      "\n",
      "public transport\n",
      "\n",
      "/\n",
      "\n",
      "indian railways\n",
      "\n",
      "/\n",
      "\n",
      "railway\n",
      "\n",
      "/\n",
      "\n",
      "Chennai\n",
      "\n",
      "/\n",
      "\n",
      "Hyderabad\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for sentence in doc.sents:\n",
    "    print(sentence.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71960a82-ef89-4100-8815-18dc0f432d1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['Article'] = df['Article'].astype(str)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    article = row['Article']\n",
    "    pattern1 = re.compile(r'\\n\\nCOMMents\\n\\n SHARE\\n\\n.*(?:\\n.*)*')\n",
    "    article = re.sub(pattern1, '', article)\n",
    "    pattern2 = re.compile(r'\\n\\| Photo Credit:.*(?:\\n.*)?')\n",
    "    article = re.sub(pattern2, '', article)\n",
    "    article = re.sub(r'\\s+', ' ', article).strip() # removing extra white spaces\n",
    "    df.at[index, 'processed_article'] = article\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbf748c3-f29c-41fd-ac6d-bca92e1bea5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "      <th>processed_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passenger vehicles wholesales rise 26.73% to r...</td>\n",
       "      <td>Domestic passenger vehicle wholesales grew 26....</td>\n",
       "      <td>Domestic passenger vehicle wholesales grew 26....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamborghini unveils Urus S at starting price o...</td>\n",
       "      <td>Automobili Lamborghini has unveiled Urus S, th...</td>\n",
       "      <td>Automobili Lamborghini has unveiled Urus S, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rupee trade arrangement to help cut transactio...</td>\n",
       "      <td>International trade in the domestic currency w...</td>\n",
       "      <td>International trade in the domestic currency w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G-20 Finance Ministers discuss debt distress, ...</td>\n",
       "      <td>G-20 countries discussed the debt distress of ...</td>\n",
       "      <td>G-20 countries discussed the debt distress of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goods exports grew 6% , imports 16.5% this fiscal</td>\n",
       "      <td>India’s goods exports declined for the second ...</td>\n",
       "      <td>India’s goods exports declined for the second ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   \n",
       "0  Passenger vehicles wholesales rise 26.73% to r...  \\\n",
       "1  Lamborghini unveils Urus S at starting price o...   \n",
       "2  Rupee trade arrangement to help cut transactio...   \n",
       "3  G-20 Finance Ministers discuss debt distress, ...   \n",
       "4  Goods exports grew 6% , imports 16.5% this fiscal   \n",
       "\n",
       "                                             Article   \n",
       "0  Domestic passenger vehicle wholesales grew 26....  \\\n",
       "1  Automobili Lamborghini has unveiled Urus S, th...   \n",
       "2  International trade in the domestic currency w...   \n",
       "3  G-20 countries discussed the debt distress of ...   \n",
       "4  India’s goods exports declined for the second ...   \n",
       "\n",
       "                                   processed_article  \n",
       "0  Domestic passenger vehicle wholesales grew 26....  \n",
       "1  Automobili Lamborghini has unveiled Urus S, th...  \n",
       "2  International trade in the domestic currency w...  \n",
       "3  G-20 countries discussed the debt distress of ...  \n",
       "4  India’s goods exports declined for the second ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3682781a-efca-4de6-8b04-817c9ecad5bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "article = df['processed_article']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad02b8fc-a1e0-40f9-8498-fa628b2d49d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indian Railways turns 170 on April 16. Forever India’s favourite carrier, the railways are as much at a crossroads today as the rest of India — reconciling the trials and tribulations of the past with a future reckoning. Perhaps the most striking symbols of Indian Railways in the current zeitgeist are the talismanic Vande Bharat Express trains. Much of this modernisation contributes to passenger comfort, but sometimes it also leads to a spectacularly short-sighted loss of beauty and cultural heritage. In cities across India, colonial-era station buildings, many of which are a syncretic mix of local culture and European styles — such as Kacheguda in Hyderabad and Egmore in Chennai — are set for modernisation that will almost certainly produce drab, mall-like monoliths. Kacheguda station in Hyderabad is one among the 1,275 railway stations slated for redevelopment under the Amrit Bharat scheme. Egmore station in Chennai will be redeveloped at a cost of ₹734 crore. On April 8, the Prime Minister laid the foundation stone for the redevelopment of Secunderabad Railway Station at a cost of about ₹720 crore. Around the country, 1,275 railway stations are slated for redevelopment under the Amrit Bharat scheme. The modernisation of railway facilities is a necessary imperative but one that has created debate for decades. When the original Beaux-Arts-style building of New York’s famous Pennsylvania (Penn) Station was demolished in 1963, there was much regret and consternation. Art historian Vincent Scully lamented: “One entered the city like a god; one scuttles in now like a rat.” My abiding fear is that the rush of modernisation coming for our classic railway heritage structures is similar: short-sighted uniform design choices that are justified at every turn as “function over form”, which leave us bereft of a unique legacy. A group of rail vloggers pose next to the Gandhinagar-Mumbai Vande Bharat Express at Mumbai Central, September 30, 2022. Determined to document for posterity the glory of our railways, and also highlight their modern-day progress, a new crop of travellers and influencers has jumped on the social travel bandwagon. With the rise in popularity of social media platforms and unfettered Internet bandwidth, these young video bloggers (vloggers) and rail influencers are using trains to take vicarious travel to the huddled masses. Viewership and engagement with such efforts increased exponentially during the pandemic as audiences starved of travel and outdoor experiences tuned in en masse to YouTube and Instagram to fulfill their wanderlust. Vishwajeet Singh Monu of VS Monu Vlogs makes Hindi language content travelling in trains to various destinations in India. These vloggers and influencers now cater to disparate and esoteric tastes. Vishwajeet Singh Monu ( VS Monu Vlogs) is the influencer from the heartland who makes Hindi language content travelling in the unreserved compartment of passenger trains one week, and in the AC class of premium trains the next. Here, aspiration is the USP. There are also channels for the more technically inclined, which describe the workings and mechanism of rail technology in layman’s terms. Some like vlogger Chinmay Kole hawk entire train journeys with no additional commentary: just the sights and sounds of travelling on a train, beamed for your edification into your living room and your mobile phone. And there is an increasing cohort of women rail vloggers and influencers, a welcome trend pointing to the all-round appeal of the railways. The social travel phenomenon is reflective of a much larger reality: Indian trains have been, and always will be, inextricably linked with the lived realities of people. But who should the massive organisation really cater to? Perhaps they are for the business and luxury traveller, who with the proliferation of affordable air travel is taking more often and more naturally to the skies? In this scenario, it is possible that premium trains are increasingly relegated to operating between nearby cities, winning out over the hassle of airport commutes and security protocols while providing seamless door-to-door connections thanks to modern urban transit systems. Or perhaps the rail network should serve the itinerant migrant populations that move between parts of the country seasonally. The railways were witness, via the Shramik Special trains, to millions of migrant workers making their way back home by any means possible during the COVID-19 lockdown in 2020. The conditions outside stations and inside the trains were appalling and unsafe, but there was no alternative for this group that suddenly found itself without jobs or an income at the height of the pandemic. During the 2020 lockdown, Shramik Special trains were used by migrant workers to travel home. Composer Vishal Dadlani noted on Twitter: “Migrant workers, most of whom have not earned a penny during lockdown, are being asked to pay for railway tickets to get to their homes.” In the coming years, these questions will remain: can the Indian Railways make such journeys less arduous and dangerous? Will railways ministers undertake inspection tours of overcrowded unreserved compartments, in addition to their well-publicised tours of Vande Bharat trains? Or, conceitedly, are Indian trains for the enthusiasts and rail fans like me, who seek an appropriate preservation of the past while awaiting the future with a combination of excitement and trepidation? We cannot be sure of all the answers, but one thing is certain: the grand story of the Indian Railways — one that has spanned nearly two centuries now — will continue, inextricably linked with the fate and fortunes of India. The writer is a research scientist whose first love is trains and the Indian Railways.\n"
     ]
    }
   ],
   "source": [
    "text = article[10]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8eef736-d5d7-4c42-8bff-cd6cd5badb23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Indian Railways turns 170 on April 16.\n",
      "Forever India’s favourite carrier, the railways are as much at a crossroads today as the rest of India — reconciling the trials and tribulations of the past with a future reckoning.\n",
      "Perhaps the most striking symbols of Indian Railways in the current zeitgeist are the talismanic Vande Bharat Express trains.\n",
      "Much of this modernisation contributes to passenger comfort, but sometimes it also leads to a spectacularly short-sighted loss of beauty and cultural heritage.\n",
      "In cities across India, colonial-era station buildings, many of which are a syncretic mix of local culture and European styles — such as Kacheguda in Hyderabad and Egmore in Chennai — are set for modernisation that will almost certainly produce drab, mall-like monoliths.\n",
      "Kacheguda station in Hyderabad is one among the 1,275 railway stations slated for redevelopment under the Amrit Bharat scheme.\n",
      "Egmore station in Chennai will be redeveloped at a cost of ₹734 crore.\n",
      "On April 8, the Prime Minister laid the foundation stone for the redevelopment of Secunderabad Railway Station at a cost of about ₹720 crore.\n",
      "Around the country, 1,275 railway stations are slated for redevelopment under the Amrit Bharat scheme.\n",
      "The modernisation of railway facilities is a necessary imperative but one that has created debate for decades.\n",
      "When the original Beaux-Arts-style building of New York’s famous Pennsylvania (Penn) Station was demolished in 1963, there was much regret and consternation.\n",
      "Art historian Vincent Scully lamented: “One entered the city like a god; one scuttles in now like a rat.”\n",
      "My abiding fear is that the rush of modernisation coming for our classic railway heritage structures is similar: short-sighted uniform design choices that are justified at every turn as “function over form”, which leave us bereft of a unique legacy.\n",
      "A group of rail vloggers pose next to the Gandhinagar-Mumbai Vande Bharat Express at Mumbai Central, September 30, 2022.\n",
      "Determined to document for posterity the glory of our railways, and also highlight their modern-day progress, a new crop of travellers and influencers has jumped on the social travel bandwagon.\n",
      "With the rise in popularity of social media platforms and unfettered Internet bandwidth, these young video bloggers (vloggers) and rail influencers are using trains to take vicarious travel to the huddled masses.\n",
      "Viewership and engagement with such efforts increased exponentially during the pandemic as audiences starved of travel and outdoor experiences tuned in en masse to YouTube and Instagram to fulfill their wanderlust.\n",
      "Vishwajeet Singh Monu of VS Monu Vlogs makes Hindi language content travelling in trains to various destinations in India.\n",
      "These vloggers and influencers now cater to disparate and esoteric tastes.\n",
      "Vishwajeet Singh Monu ( VS Monu Vlogs) is the influencer from the heartland who makes Hindi language content travelling in the unreserved compartment of passenger trains one week, and in the AC class of premium trains the next.\n",
      "Here, aspiration is the USP.\n",
      "There are also channels for the more technically inclined, which describe the workings and mechanism of rail technology in layman’s terms.\n",
      "Some like vlogger Chinmay Kole hawk entire train journeys with no additional commentary: just the sights and sounds of travelling on a train, beamed for your edification into your living room and your mobile phone.\n",
      "And there is an increasing cohort of women rail vloggers and influencers, a welcome trend pointing to the all-round appeal of the railways.\n",
      "The social travel phenomenon is reflective of a much larger reality: Indian trains have been, and always will be, inextricably linked with the lived realities of people.\n",
      "But who should the massive organisation really cater to?\n",
      "Perhaps they are for the business and luxury traveller, who with the proliferation of affordable air travel is taking more often and more naturally to the skies?\n",
      "In this scenario, it is possible that premium trains are increasingly relegated to operating between nearby cities, winning out over the hassle of airport commutes and security protocols while providing seamless door-to-door connections thanks to modern urban transit systems.\n",
      "Or perhaps the rail network should serve the itinerant migrant populations that move between parts of the country seasonally.\n",
      "The railways were witness, via the Shramik Special trains, to millions of migrant workers making their way back home by any means possible during the COVID-19 lockdown in 2020.\n",
      "The conditions outside stations and inside the trains were appalling and unsafe, but there was no alternative for this group that suddenly found itself without jobs or an income at the height of the pandemic.\n",
      "During the 2020 lockdown, Shramik Special trains were used by migrant workers to travel home.\n",
      "Composer Vishal Dadlani noted on Twitter: “Migrant workers, most of whom have not earned a penny during lockdown, are being asked to pay for railway tickets to get to their homes.”\n",
      "In the coming years, these questions will remain: can the Indian Railways make such journeys less arduous and dangerous?\n",
      "Will railways ministers undertake inspection tours of overcrowded unreserved compartments, in addition to their well-publicised tours of Vande Bharat trains?\n",
      "Or, conceitedly, are Indian trains for the enthusiasts and rail fans like me, who seek an appropriate preservation of the past while awaiting the future with a combination of excitement and trepidation?\n",
      "We cannot be sure of all the answers, but one thing is certain: the grand story of the Indian Railways — one that has spanned nearly two centuries now — will continue, inextricably linked with the fate and fortunes of India.\n",
      "The writer is a research scientist whose first love is trains and the Indian Railways.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "for sentence in doc.sents:\n",
    "    print(sentence.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17d2134c-c4d7-4484-804a-ccf3e70e71e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2316, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec0c7f73-9f78-442e-a499-46c052b0f3fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Detect non-English articles\n",
    "non_english = []\n",
    "for index, row in df.iterrows():\n",
    "    article = row['processed_article']\n",
    "    lang = detect(article)\n",
    "    if lang != 'en':\n",
    "        non_english.append(index)\n",
    "\n",
    "# Drop rows with non-English articles\n",
    "df.drop(non_english, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ee01beb-dcac-450d-bf78-a84fd8976fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[437, 439]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39c96ee6-1bf7-44bc-bdd0-35abd5ea4d45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2314, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d70ccada-d1fc-46ef-aa26-53c579d78262",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "      <th>processed_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passenger vehicles wholesales rise 26.73% to r...</td>\n",
       "      <td>Domestic passenger vehicle wholesales grew 26....</td>\n",
       "      <td>Domestic passenger vehicle wholesales grew 26....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamborghini unveils Urus S at starting price o...</td>\n",
       "      <td>Automobili Lamborghini has unveiled Urus S, th...</td>\n",
       "      <td>Automobili Lamborghini has unveiled Urus S, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rupee trade arrangement to help cut transactio...</td>\n",
       "      <td>International trade in the domestic currency w...</td>\n",
       "      <td>International trade in the domestic currency w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G-20 Finance Ministers discuss debt distress, ...</td>\n",
       "      <td>G-20 countries discussed the debt distress of ...</td>\n",
       "      <td>G-20 countries discussed the debt distress of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goods exports grew 6% , imports 16.5% this fiscal</td>\n",
       "      <td>India’s goods exports declined for the second ...</td>\n",
       "      <td>India’s goods exports declined for the second ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   \n",
       "0  Passenger vehicles wholesales rise 26.73% to r...  \\\n",
       "1  Lamborghini unveils Urus S at starting price o...   \n",
       "2  Rupee trade arrangement to help cut transactio...   \n",
       "3  G-20 Finance Ministers discuss debt distress, ...   \n",
       "4  Goods exports grew 6% , imports 16.5% this fiscal   \n",
       "\n",
       "                                             Article   \n",
       "0  Domestic passenger vehicle wholesales grew 26....  \\\n",
       "1  Automobili Lamborghini has unveiled Urus S, th...   \n",
       "2  International trade in the domestic currency w...   \n",
       "3  G-20 countries discussed the debt distress of ...   \n",
       "4  India’s goods exports declined for the second ...   \n",
       "\n",
       "                                   processed_article  \n",
       "0  Domestic passenger vehicle wholesales grew 26....  \n",
       "1  Automobili Lamborghini has unveiled Urus S, th...  \n",
       "2  International trade in the domestic currency w...  \n",
       "3  G-20 countries discussed the debt distress of ...  \n",
       "4  India’s goods exports declined for the second ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6a44f2d-b697-4195-845e-eaf7e7151011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.to_csv('Articles.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81c51c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "      <th>processed_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passenger vehicles wholesales rise 26.73% to r...</td>\n",
       "      <td>Domestic passenger vehicle wholesales grew 26....</td>\n",
       "      <td>Domestic passenger vehicle wholesales grew 26....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamborghini unveils Urus S at starting price o...</td>\n",
       "      <td>Automobili Lamborghini has unveiled Urus S, th...</td>\n",
       "      <td>Automobili Lamborghini has unveiled Urus S, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rupee trade arrangement to help cut transactio...</td>\n",
       "      <td>International trade in the domestic currency w...</td>\n",
       "      <td>International trade in the domestic currency w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G-20 Finance Ministers discuss debt distress, ...</td>\n",
       "      <td>G-20 countries discussed the debt distress of ...</td>\n",
       "      <td>G-20 countries discussed the debt distress of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goods exports grew 6% , imports 16.5% this fiscal</td>\n",
       "      <td>India’s goods exports declined for the second ...</td>\n",
       "      <td>India’s goods exports declined for the second ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   \n",
       "0  Passenger vehicles wholesales rise 26.73% to r...  \\\n",
       "1  Lamborghini unveils Urus S at starting price o...   \n",
       "2  Rupee trade arrangement to help cut transactio...   \n",
       "3  G-20 Finance Ministers discuss debt distress, ...   \n",
       "4  Goods exports grew 6% , imports 16.5% this fiscal   \n",
       "\n",
       "                                             Article   \n",
       "0  Domestic passenger vehicle wholesales grew 26....  \\\n",
       "1  Automobili Lamborghini has unveiled Urus S, th...   \n",
       "2  International trade in the domestic currency w...   \n",
       "3  G-20 countries discussed the debt distress of ...   \n",
       "4  India’s goods exports declined for the second ...   \n",
       "\n",
       "                                   processed_article  \n",
       "0  Domestic passenger vehicle wholesales grew 26....  \n",
       "1  Automobili Lamborghini has unveiled Urus S, th...  \n",
       "2  International trade in the domestic currency w...  \n",
       "3  G-20 countries discussed the debt distress of ...  \n",
       "4  India’s goods exports declined for the second ...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9999b09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.is_alpha and len(token)>2]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b4cce220",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_article'] = df['processed_article'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff607a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "      <th>processed_article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passenger vehicles wholesales rise 26.73% to r...</td>\n",
       "      <td>Domestic passenger vehicle wholesales grew 26....</td>\n",
       "      <td>domestic passenger vehicle wholesale grow reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamborghini unveils Urus S at starting price o...</td>\n",
       "      <td>Automobili Lamborghini has unveiled Urus S, th...</td>\n",
       "      <td>Automobili Lamborghini unveil Urus successor o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rupee trade arrangement to help cut transactio...</td>\n",
       "      <td>International trade in the domestic currency w...</td>\n",
       "      <td>international trade domestic currency help red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G-20 Finance Ministers discuss debt distress, ...</td>\n",
       "      <td>G-20 countries discussed the debt distress of ...</td>\n",
       "      <td>country discuss debt distress poor middle inco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goods exports grew 6% , imports 16.5% this fiscal</td>\n",
       "      <td>India’s goods exports declined for the second ...</td>\n",
       "      <td>India good export decline second successive mo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   \n",
       "0  Passenger vehicles wholesales rise 26.73% to r...  \\\n",
       "1  Lamborghini unveils Urus S at starting price o...   \n",
       "2  Rupee trade arrangement to help cut transactio...   \n",
       "3  G-20 Finance Ministers discuss debt distress, ...   \n",
       "4  Goods exports grew 6% , imports 16.5% this fiscal   \n",
       "\n",
       "                                             Article   \n",
       "0  Domestic passenger vehicle wholesales grew 26....  \\\n",
       "1  Automobili Lamborghini has unveiled Urus S, th...   \n",
       "2  International trade in the domestic currency w...   \n",
       "3  G-20 countries discussed the debt distress of ...   \n",
       "4  India’s goods exports declined for the second ...   \n",
       "\n",
       "                                   processed_article  \n",
       "0  domestic passenger vehicle wholesale grow reco...  \n",
       "1  Automobili Lamborghini unveil Urus successor o...  \n",
       "2  international trade domestic currency help red...  \n",
       "3  country discuss debt distress poor middle inco...  \n",
       "4  India good export decline second successive mo...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0744b677",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['processed_article'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02fa7e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    keywords = []\n",
    "    for token in doc:\n",
    "        if not token.is_stop and token.is_alpha and len(token) > 2:\n",
    "            keywords.append(token.lemma_)\n",
    "    return list(set(keywords))\n",
    "\n",
    "df['keywords'] = df['processed_article'].apply(extract_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37aec5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "      <th>processed_article</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passenger vehicles wholesales rise 26.73% to r...</td>\n",
       "      <td>Domestic passenger vehicle wholesales grew 26....</td>\n",
       "      <td>domestic passenger vehicle wholesale grow reco...</td>\n",
       "      <td>[start, Aggarwal, surge, industry, efficient, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamborghini unveils Urus S at starting price o...</td>\n",
       "      <td>Automobili Lamborghini has unveiled Urus S, th...</td>\n",
       "      <td>Automobili Lamborghini unveil Urus successor o...</td>\n",
       "      <td>[start, Chairman, speed, sporty, endure, combi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rupee trade arrangement to help cut transactio...</td>\n",
       "      <td>International trade in the domestic currency w...</td>\n",
       "      <td>international trade domestic currency help red...</td>\n",
       "      <td>[Kolkata, industry, HDFC, Bank, body, July, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G-20 Finance Ministers discuss debt distress, ...</td>\n",
       "      <td>G-20 countries discussed the debt distress of ...</td>\n",
       "      <td>country discuss debt distress poor middle inco...</td>\n",
       "      <td>[key, criticism, offer, distressed, Central, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goods exports grew 6% , imports 16.5% this fiscal</td>\n",
       "      <td>India’s goods exports declined for the second ...</td>\n",
       "      <td>India good export decline second successive mo...</td>\n",
       "      <td>[gap, insignificant, Goods, surge, combine, pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   \n",
       "0  Passenger vehicles wholesales rise 26.73% to r...  \\\n",
       "1  Lamborghini unveils Urus S at starting price o...   \n",
       "2  Rupee trade arrangement to help cut transactio...   \n",
       "3  G-20 Finance Ministers discuss debt distress, ...   \n",
       "4  Goods exports grew 6% , imports 16.5% this fiscal   \n",
       "\n",
       "                                             Article   \n",
       "0  Domestic passenger vehicle wholesales grew 26....  \\\n",
       "1  Automobili Lamborghini has unveiled Urus S, th...   \n",
       "2  International trade in the domestic currency w...   \n",
       "3  G-20 countries discussed the debt distress of ...   \n",
       "4  India’s goods exports declined for the second ...   \n",
       "\n",
       "                                   processed_article   \n",
       "0  domestic passenger vehicle wholesale grow reco...  \\\n",
       "1  Automobili Lamborghini unveil Urus successor o...   \n",
       "2  international trade domestic currency help red...   \n",
       "3  country discuss debt distress poor middle inco...   \n",
       "4  India good export decline second successive mo...   \n",
       "\n",
       "                                            keywords  \n",
       "0  [start, Aggarwal, surge, industry, efficient, ...  \n",
       "1  [start, Chairman, speed, sporty, endure, combi...  \n",
       "2  [Kolkata, industry, HDFC, Bank, body, July, tr...  \n",
       "3  [key, criticism, offer, distressed, Central, S...  \n",
       "4  [gap, insignificant, Goods, surge, combine, pe...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3a8cba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9a71171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "      <th>processed_article</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passenger vehicles wholesales rise 26.73% to r...</td>\n",
       "      <td>Domestic passenger vehicle wholesales grew 26....</td>\n",
       "      <td>domestic passenger vehicle wholesale grow reco...</td>\n",
       "      <td>[start, Aggarwal, surge, industry, efficient, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamborghini unveils Urus S at starting price o...</td>\n",
       "      <td>Automobili Lamborghini has unveiled Urus S, th...</td>\n",
       "      <td>Automobili Lamborghini unveil Urus successor o...</td>\n",
       "      <td>[start, Chairman, speed, sporty, endure, combi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rupee trade arrangement to help cut transactio...</td>\n",
       "      <td>International trade in the domestic currency w...</td>\n",
       "      <td>international trade domestic currency help red...</td>\n",
       "      <td>[Kolkata, industry, HDFC, Bank, body, July, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G-20 Finance Ministers discuss debt distress, ...</td>\n",
       "      <td>G-20 countries discussed the debt distress of ...</td>\n",
       "      <td>country discuss debt distress poor middle inco...</td>\n",
       "      <td>[key, criticism, offer, distressed, Central, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goods exports grew 6% , imports 16.5% this fiscal</td>\n",
       "      <td>India’s goods exports declined for the second ...</td>\n",
       "      <td>India good export decline second successive mo...</td>\n",
       "      <td>[gap, insignificant, Goods, surge, combine, pe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   \n",
       "0  Passenger vehicles wholesales rise 26.73% to r...  \\\n",
       "1  Lamborghini unveils Urus S at starting price o...   \n",
       "2  Rupee trade arrangement to help cut transactio...   \n",
       "3  G-20 Finance Ministers discuss debt distress, ...   \n",
       "4  Goods exports grew 6% , imports 16.5% this fiscal   \n",
       "\n",
       "                                             Article   \n",
       "0  Domestic passenger vehicle wholesales grew 26....  \\\n",
       "1  Automobili Lamborghini has unveiled Urus S, th...   \n",
       "2  International trade in the domestic currency w...   \n",
       "3  G-20 countries discussed the debt distress of ...   \n",
       "4  India’s goods exports declined for the second ...   \n",
       "\n",
       "                                   processed_article   \n",
       "0  domestic passenger vehicle wholesale grow reco...  \\\n",
       "1  Automobili Lamborghini unveil Urus successor o...   \n",
       "2  international trade domestic currency help red...   \n",
       "3  country discuss debt distress poor middle inco...   \n",
       "4  India good export decline second successive mo...   \n",
       "\n",
       "                                            keywords  \n",
       "0  [start, Aggarwal, surge, industry, efficient, ...  \n",
       "1  [start, Chairman, speed, sporty, endure, combi...  \n",
       "2  [Kolkata, industry, HDFC, Bank, body, July, tr...  \n",
       "3  [key, criticism, offer, distressed, Central, S...  \n",
       "4  [gap, insignificant, Goods, surge, combine, pe...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ba32790b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['processed_article'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e784a965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['keywords'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "33c53ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['keywords'] = df['keywords'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1eb8ea11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['keywords'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f9f2bdbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14467\n"
     ]
    }
   ],
   "source": [
    "max_length = max(len(seq) for seq in df['processed_article'])\n",
    "print(max_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad9f3a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text(text):\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=max_length,\n",
    "        return_tensors='tf'\n",
    "    )\n",
    "    return encoding['input_ids'][0], encoding['attention_mask'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1141379",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 17:11:01.515834: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-15 17:11:01.516029: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-15 17:11:01.516065: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-15 17:11:02.835235: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-15 17:11:02.835319: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-15 17:11:02.835326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-15 17:11:02.835404: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-15 17:11:02.835444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "df[['tokenized_article', 'attention_mask']] = df['processed_article'].apply(tokenize_text).apply(pd.Series)\n",
    "df[['tokenized_keywords', 'attention_mask']] = df['keywords'].apply(tokenize_text).apply(pd.Series)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71a89021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Article</th>\n",
       "      <th>processed_article</th>\n",
       "      <th>keywords</th>\n",
       "      <th>tokenized_article</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>tokenized_keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Passenger vehicles wholesales rise 26.73% to r...</td>\n",
       "      <td>Domestic passenger vehicle wholesales grew 26....</td>\n",
       "      <td>domestic passenger vehicle wholesale grow reco...</td>\n",
       "      <td>start Aggarwal surge industry efficient Direct...</td>\n",
       "      <td>(tf.Tensor(101, shape=(), dtype=int32), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(1, shape=(), dtype=int32), tf.Tenso...</td>\n",
       "      <td>(tf.Tensor(101, shape=(), dtype=int32), tf.Ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lamborghini unveils Urus S at starting price o...</td>\n",
       "      <td>Automobili Lamborghini has unveiled Urus S, th...</td>\n",
       "      <td>Automobili Lamborghini unveil Urus successor o...</td>\n",
       "      <td>start Chairman speed sporty endure combine app...</td>\n",
       "      <td>(tf.Tensor(101, shape=(), dtype=int32), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(1, shape=(), dtype=int32), tf.Tenso...</td>\n",
       "      <td>(tf.Tensor(101, shape=(), dtype=int32), tf.Ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rupee trade arrangement to help cut transactio...</td>\n",
       "      <td>International trade in the domestic currency w...</td>\n",
       "      <td>international trade domestic currency help red...</td>\n",
       "      <td>Kolkata industry HDFC Bank body July trade tod...</td>\n",
       "      <td>(tf.Tensor(101, shape=(), dtype=int32), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(1, shape=(), dtype=int32), tf.Tenso...</td>\n",
       "      <td>(tf.Tensor(101, shape=(), dtype=int32), tf.Ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G-20 Finance Ministers discuss debt distress, ...</td>\n",
       "      <td>G-20 countries discussed the debt distress of ...</td>\n",
       "      <td>country discuss debt distress poor middle inco...</td>\n",
       "      <td>key criticism offer distressed Central Shaktik...</td>\n",
       "      <td>(tf.Tensor(101, shape=(), dtype=int32), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(1, shape=(), dtype=int32), tf.Tenso...</td>\n",
       "      <td>(tf.Tensor(101, shape=(), dtype=int32), tf.Ten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Goods exports grew 6% , imports 16.5% this fiscal</td>\n",
       "      <td>India’s goods exports declined for the second ...</td>\n",
       "      <td>India good export decline second successive mo...</td>\n",
       "      <td>gap insignificant Goods surge combine peg Baro...</td>\n",
       "      <td>(tf.Tensor(101, shape=(), dtype=int32), tf.Ten...</td>\n",
       "      <td>(tf.Tensor(1, shape=(), dtype=int32), tf.Tenso...</td>\n",
       "      <td>(tf.Tensor(101, shape=(), dtype=int32), tf.Ten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title   \n",
       "0  Passenger vehicles wholesales rise 26.73% to r...  \\\n",
       "1  Lamborghini unveils Urus S at starting price o...   \n",
       "2  Rupee trade arrangement to help cut transactio...   \n",
       "3  G-20 Finance Ministers discuss debt distress, ...   \n",
       "4  Goods exports grew 6% , imports 16.5% this fiscal   \n",
       "\n",
       "                                             Article   \n",
       "0  Domestic passenger vehicle wholesales grew 26....  \\\n",
       "1  Automobili Lamborghini has unveiled Urus S, th...   \n",
       "2  International trade in the domestic currency w...   \n",
       "3  G-20 countries discussed the debt distress of ...   \n",
       "4  India’s goods exports declined for the second ...   \n",
       "\n",
       "                                   processed_article   \n",
       "0  domestic passenger vehicle wholesale grow reco...  \\\n",
       "1  Automobili Lamborghini unveil Urus successor o...   \n",
       "2  international trade domestic currency help red...   \n",
       "3  country discuss debt distress poor middle inco...   \n",
       "4  India good export decline second successive mo...   \n",
       "\n",
       "                                            keywords   \n",
       "0  start Aggarwal surge industry efficient Direct...  \\\n",
       "1  start Chairman speed sporty endure combine app...   \n",
       "2  Kolkata industry HDFC Bank body July trade tod...   \n",
       "3  key criticism offer distressed Central Shaktik...   \n",
       "4  gap insignificant Goods surge combine peg Baro...   \n",
       "\n",
       "                                   tokenized_article   \n",
       "0  (tf.Tensor(101, shape=(), dtype=int32), tf.Ten...  \\\n",
       "1  (tf.Tensor(101, shape=(), dtype=int32), tf.Ten...   \n",
       "2  (tf.Tensor(101, shape=(), dtype=int32), tf.Ten...   \n",
       "3  (tf.Tensor(101, shape=(), dtype=int32), tf.Ten...   \n",
       "4  (tf.Tensor(101, shape=(), dtype=int32), tf.Ten...   \n",
       "\n",
       "                                      attention_mask   \n",
       "0  (tf.Tensor(1, shape=(), dtype=int32), tf.Tenso...  \\\n",
       "1  (tf.Tensor(1, shape=(), dtype=int32), tf.Tenso...   \n",
       "2  (tf.Tensor(1, shape=(), dtype=int32), tf.Tenso...   \n",
       "3  (tf.Tensor(1, shape=(), dtype=int32), tf.Tenso...   \n",
       "4  (tf.Tensor(1, shape=(), dtype=int32), tf.Tenso...   \n",
       "\n",
       "                                  tokenized_keywords  \n",
       "0  (tf.Tensor(101, shape=(), dtype=int32), tf.Ten...  \n",
       "1  (tf.Tensor(101, shape=(), dtype=int32), tf.Ten...  \n",
       "2  (tf.Tensor(101, shape=(), dtype=int32), tf.Ten...  \n",
       "3  (tf.Tensor(101, shape=(), dtype=int32), tf.Ten...  \n",
       "4  (tf.Tensor(101, shape=(), dtype=int32), tf.Ten...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "59dea5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert titles to numerical labels\n",
    "def convert_titles_to_labels(titles):\n",
    "    label_map = {}\n",
    "    labels = np.unique(titles)\n",
    "    for idx, label in enumerate(labels):\n",
    "        label_map[label] = idx\n",
    "    label_ids = np.array([label_map[label] for label in titles], dtype=np.int32)\n",
    "    return label_ids, label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "926c5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_labels, label_map = convert_titles_to_labels(df['Title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93bab329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "tokenized_article_padded = pad_sequences(df['tokenized_article'], maxlen=max_length, padding='post')\n",
    "attention_mask_padded = pad_sequences(df['attention_mask'], maxlen=max_length, padding='post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "28d575ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the split indices\n",
    "train_size = int(len(tokenized_article_padded) * 0.8)\n",
    "valid_size = int(len(tokenized_article_padded) * 0.1)\n",
    "\n",
    "# Split the data and attention masks\n",
    "train_data = tokenized_article_padded[:train_size]\n",
    "train_attention_masks = attention_mask_padded[:train_size]\n",
    "train_labels = title_labels[:train_size]\n",
    "\n",
    "valid_data = tokenized_article_padded[train_size:train_size + valid_size]\n",
    "valid_attention_masks = attention_mask_padded[train_size:train_size + valid_size]\n",
    "valid_labels = title_labels[train_size:train_size + valid_size]\n",
    "\n",
    "test_data = tokenized_article_padded[train_size + valid_size:]\n",
    "test_attention_masks = attention_mask_padded[train_size + valid_size:]\n",
    "test_labels = title_labels[train_size + valid_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "98b524d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertModel\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the BERT model architecture\n",
    "def build_model():\n",
    "    input_ids = tf.keras.layers.Input(shape=(14467,), dtype=tf.int32)\n",
    "    attention_mask = tf.keras.layers.Input(shape=(14467,), dtype=tf.int32)\n",
    "    \n",
    "    # Load the pre-trained BERT model\n",
    "    bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "    \n",
    "    # Freeze the BERT model's layers to prevent training\n",
    "    bert_model.trainable = False\n",
    "    \n",
    "    # Retrieve the BERT outputs\n",
    "    bert_outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = bert_outputs.pooler_output\n",
    "    \n",
    "    # Add a fully connected layer for classification\n",
    "    output = tf.keras.layers.Dense(len(label_map), activation='softmax')(pooled_output)\n",
    "    \n",
    "    # Construct the model\n",
    "    model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the BERT model\n",
    "model = build_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "693cb590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c3ccc374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-15 17:36:29.945907: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 74.85GiB (rounded to 80368930304)requested by op model_1/tf_bert_model_1/bert/encoder/layer_._0/attention/self/MatMul\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-05-15 17:36:29.945996: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
      "2023-05-15 17:36:29.946008: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 57, Chunks in use: 56. 14.2KiB allocated for chunks. 14.0KiB in use in bin. 348B client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946012: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 2, Chunks in use: 0. 1.5KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946016: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946019: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 110, Chunks in use: 110. 330.0KiB allocated for chunks. 330.0KiB in use in bin. 330.0KiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946022: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 2, Chunks in use: 2. 11.8KiB allocated for chunks. 11.8KiB in use in bin. 9.0KiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946025: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 17, Chunks in use: 16. 199.2KiB allocated for chunks. 189.5KiB in use in bin. 177.2KiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946028: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 1, Chunks in use: 1. 18.0KiB allocated for chunks. 18.0KiB in use in bin. 12.0KiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946031: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 1, Chunks in use: 0. 48.0KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946034: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946036: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 1, Chunks in use: 0. 129.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946039: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946042: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 1, Chunks in use: 1. 707.8KiB allocated for chunks. 707.8KiB in use in bin. 452.1KiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946044: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946048: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 51, Chunks in use: 50. 115.88MiB allocated for chunks. 113.63MiB in use in bin. 111.75MiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946051: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 5, Chunks in use: 4. 31.70MiB allocated for chunks. 27.12MiB in use in bin. 27.12MiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946054: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 25, Chunks in use: 24. 235.58MiB allocated for chunks. 226.61MiB in use in bin. 213.78MiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946057: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 16.24MiB allocated for chunks. 16.24MiB in use in bin. 9.00MiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946060: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 2, Chunks in use: 0. 93.86MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946063: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 4, Chunks in use: 1. 431.93MiB allocated for chunks. 89.42MiB in use in bin. 89.42MiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946066: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 0. 148.16MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946070: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 6, Chunks in use: 4. 2.25GiB allocated for chunks. 1.32GiB in use in bin. 1.32GiB client-requested in use in bin.\n",
      "2023-05-15 17:36:29.946073: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 74.85GiB was 256.00MiB, Chunk State: \n",
      "2023-05-15 17:36:29.946082: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 339.07MiB | Requested Size: 339.07MiB | in_use: 0 | bin_num: 20, prev:   Size: 339.07MiB | Requested Size: 339.07MiB | in_use: 1 | bin_num: -1, next:   Size: 339.07MiB | Requested Size: 339.07MiB | in_use: 1 | bin_num: -1\n",
      "2023-05-15 17:36:29.946086: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 612.87MiB | Requested Size: 3.0KiB | in_use: 0 | bin_num: 20, prev:   Size: 339.07MiB | Requested Size: 339.07MiB | in_use: 1 | bin_num: -1\n",
      "2023-05-15 17:36:29.946088: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 3547332608\n",
      "2023-05-15 17:36:29.946093: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00000 of size 1280 next 1\n",
      "2023-05-15 17:36:29.946095: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00500 of size 256 next 2\n",
      "2023-05-15 17:36:29.946097: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00600 of size 256 next 3\n",
      "2023-05-15 17:36:29.946099: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00700 of size 256 next 4\n",
      "2023-05-15 17:36:29.946101: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00800 of size 256 next 6\n",
      "2023-05-15 17:36:29.946103: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00900 of size 256 next 5\n",
      "2023-05-15 17:36:29.946105: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00a00 of size 256 next 15\n",
      "2023-05-15 17:36:29.946107: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00b00 of size 256 next 19\n",
      "2023-05-15 17:36:29.946109: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00c00 of size 256 next 7\n",
      "2023-05-15 17:36:29.946111: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00d00 of size 256 next 46\n",
      "2023-05-15 17:36:29.946113: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00e00 of size 256 next 36\n",
      "2023-05-15 17:36:29.946115: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e00f00 of size 256 next 31\n",
      "2023-05-15 17:36:29.946117: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01000 of size 256 next 40\n",
      "2023-05-15 17:36:29.946119: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01100 of size 256 next 8\n",
      "2023-05-15 17:36:29.946121: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01200 of size 256 next 13\n",
      "2023-05-15 17:36:29.946123: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01300 of size 256 next 28\n",
      "2023-05-15 17:36:29.946126: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01400 of size 256 next 173\n",
      "2023-05-15 17:36:29.946128: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01500 of size 256 next 10\n",
      "2023-05-15 17:36:29.946130: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01600 of size 256 next 30\n",
      "2023-05-15 17:36:29.946132: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01700 of size 256 next 20\n",
      "2023-05-15 17:36:29.946134: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01800 of size 256 next 21\n",
      "2023-05-15 17:36:29.946136: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01900 of size 256 next 18\n",
      "2023-05-15 17:36:29.946138: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01a00 of size 256 next 200\n",
      "2023-05-15 17:36:29.946140: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 513e01b00 of size 768 next 29\n",
      "2023-05-15 17:36:29.946142: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01e00 of size 256 next 60\n",
      "2023-05-15 17:36:29.946144: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e01f00 of size 256 next 214\n",
      "2023-05-15 17:36:29.946146: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 513e02000 of size 256 next 45\n",
      "2023-05-15 17:36:29.946148: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e02100 of size 256 next 11\n",
      "2023-05-15 17:36:29.946152: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 513e02200 of size 768 next 22\n",
      "2023-05-15 17:36:29.946154: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e02500 of size 256 next 14\n",
      "2023-05-15 17:36:29.946156: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e02600 of size 256 next 24\n",
      "2023-05-15 17:36:29.946158: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e02700 of size 256 next 25\n",
      "2023-05-15 17:36:29.946160: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e02800 of size 256 next 16\n",
      "2023-05-15 17:36:29.946167: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e02900 of size 9472 next 219\n",
      "2023-05-15 17:36:29.946170: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e04e00 of size 9472 next 217\n",
      "2023-05-15 17:36:29.946172: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 513e07300 of size 9984 next 37\n",
      "2023-05-15 17:36:29.946174: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e09a00 of size 256 next 42\n",
      "2023-05-15 17:36:29.946176: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e09b00 of size 256 next 44\n",
      "2023-05-15 17:36:29.946178: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 513e09c00 of size 49152 next 215\n",
      "2023-05-15 17:36:29.946180: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e15c00 of size 256 next 233\n",
      "2023-05-15 17:36:29.946182: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e15d00 of size 256 next 192\n",
      "2023-05-15 17:36:29.946184: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e15e00 of size 256 next 67\n",
      "2023-05-15 17:36:29.946186: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e15f00 of size 256 next 228\n",
      "2023-05-15 17:36:29.946188: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e16000 of size 256 next 113\n",
      "2023-05-15 17:36:29.946190: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e16100 of size 256 next 231\n",
      "2023-05-15 17:36:29.946192: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e16200 of size 256 next 232\n",
      "2023-05-15 17:36:29.946195: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e16300 of size 256 next 442\n",
      "2023-05-15 17:36:29.946198: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e16400 of size 256 next 366\n",
      "2023-05-15 17:36:29.946204: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e16500 of size 256 next 241\n",
      "2023-05-15 17:36:29.946206: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e16600 of size 256 next 437\n",
      "2023-05-15 17:36:29.946208: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 513e16700 of size 256 next 225\n",
      "2023-05-15 17:36:29.946210: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 513e16800 of size 4807168 next 220\n",
      "2023-05-15 17:36:29.946215: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142ac200 of size 3072 next 243\n",
      "2023-05-15 17:36:29.946218: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142ace00 of size 3072 next 250\n",
      "2023-05-15 17:36:29.946221: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142ada00 of size 3072 next 224\n",
      "2023-05-15 17:36:29.946223: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 5142ae600 of size 132352 next 230\n",
      "2023-05-15 17:36:29.946226: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142ceb00 of size 3072 next 245\n",
      "2023-05-15 17:36:29.946228: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142cf700 of size 3072 next 235\n",
      "2023-05-15 17:36:29.946230: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142d0300 of size 3072 next 237\n",
      "2023-05-15 17:36:29.946232: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142d0f00 of size 3072 next 236\n",
      "2023-05-15 17:36:29.946234: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142d1b00 of size 3072 next 255\n",
      "2023-05-15 17:36:29.946237: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142d2700 of size 3072 next 254\n",
      "2023-05-15 17:36:29.946239: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142d3300 of size 3072 next 263\n",
      "2023-05-15 17:36:29.946241: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142d3f00 of size 3072 next 258\n",
      "2023-05-15 17:36:29.946243: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142d4b00 of size 3072 next 265\n",
      "2023-05-15 17:36:29.946245: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142d5700 of size 3072 next 267\n",
      "2023-05-15 17:36:29.946248: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142d6300 of size 12288 next 252\n",
      "2023-05-15 17:36:29.946250: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142d9300 of size 3072 next 260\n",
      "2023-05-15 17:36:29.946252: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142d9f00 of size 3072 next 275\n",
      "2023-05-15 17:36:29.946254: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142dab00 of size 3072 next 279\n",
      "2023-05-15 17:36:29.946256: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5142db700 of size 5888 next 175\n",
      "2023-05-15 17:36:29.946259: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 5142dce00 of size 155354112 next 112\n",
      "2023-05-15 17:36:29.946261: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 51d705200 of size 9437184 next 305\n",
      "2023-05-15 17:36:29.946264: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 51e005200 of size 2359296 next 313\n",
      "2023-05-15 17:36:29.946266: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 51e245200 of size 2359296 next 322\n",
      "2023-05-15 17:36:29.946268: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 51e485200 of size 2359296 next 327\n",
      "2023-05-15 17:36:29.946270: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 51e6c5200 of size 2359296 next 321\n",
      "2023-05-15 17:36:29.946272: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 51e905200 of size 9437184 next 319\n",
      "2023-05-15 17:36:29.946274: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 51f205200 of size 9437184 next 323\n",
      "2023-05-15 17:36:29.946276: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 51fb05200 of size 2359296 next 330\n",
      "2023-05-15 17:36:29.946279: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 51fd45200 of size 2359296 next 342\n",
      "2023-05-15 17:36:29.946281: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 51ff85200 of size 2359296 next 347\n",
      "2023-05-15 17:36:29.946283: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5201c5200 of size 2359296 next 338\n",
      "2023-05-15 17:36:29.946285: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 520405200 of size 9437184 next 336\n",
      "2023-05-15 17:36:29.946287: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 520d05200 of size 9437184 next 340\n",
      "2023-05-15 17:36:29.946289: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 521605200 of size 2359296 next 331\n",
      "2023-05-15 17:36:29.946291: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 521845200 of size 2359296 next 357\n",
      "2023-05-15 17:36:29.946293: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 521a85200 of size 2359296 next 363\n",
      "2023-05-15 17:36:29.946295: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 521cc5200 of size 2359296 next 353\n",
      "2023-05-15 17:36:29.946298: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 521f05200 of size 9437184 next 337\n",
      "2023-05-15 17:36:29.946300: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 522805200 of size 9437184 next 356\n",
      "2023-05-15 17:36:29.946302: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 523105200 of size 2359296 next 361\n",
      "2023-05-15 17:36:29.946305: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 523345200 of size 2359296 next 362\n",
      "2023-05-15 17:36:29.946307: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 523585200 of size 2359296 next 379\n",
      "2023-05-15 17:36:29.946309: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5237c5200 of size 2359296 next 370\n",
      "2023-05-15 17:36:29.946311: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 523a05200 of size 9437184 next 365\n",
      "2023-05-15 17:36:29.946313: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 524305200 of size 9437184 next 372\n",
      "2023-05-15 17:36:29.946316: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 524c05200 of size 2359296 next 377\n",
      "2023-05-15 17:36:29.946318: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 524e45200 of size 2359296 next 389\n",
      "2023-05-15 17:36:29.946320: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 525085200 of size 2359296 next 390\n",
      "2023-05-15 17:36:29.946322: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5252c5200 of size 2359296 next 385\n",
      "2023-05-15 17:36:29.946324: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 525505200 of size 17031168 next 136\n",
      "2023-05-15 17:36:29.946326: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 526543200 of size 132120576 next 210\n",
      "2023-05-15 17:36:29.946328: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 52e343200 of size 2359296 next 222\n",
      "2023-05-15 17:36:29.946330: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 52e583200 of size 7108608 next 124\n",
      "2023-05-15 17:36:29.946333: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 52ec4aa00 of size 9406464 next 205\n",
      "2023-05-15 17:36:29.946335: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 52f543200 of size 2359296 next 240\n",
      "2023-05-15 17:36:29.946337: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 52f783200 of size 2359296 next 247\n",
      "2023-05-15 17:36:29.946339: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 52f9c3200 of size 2359296 next 251\n",
      "2023-05-15 17:36:29.946341: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 52fc03200 of size 2359296 next 227\n",
      "2023-05-15 17:36:29.946343: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 52fe43200 of size 47185920 next 148\n",
      "2023-05-15 17:36:29.946345: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b43200 of size 3072 next 276\n",
      "2023-05-15 17:36:29.946347: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b43e00 of size 3072 next 282\n",
      "2023-05-15 17:36:29.946349: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b44a00 of size 3072 next 285\n",
      "2023-05-15 17:36:29.946351: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b45600 of size 3072 next 288\n",
      "2023-05-15 17:36:29.946353: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b46200 of size 12288 next 287\n",
      "2023-05-15 17:36:29.946356: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b49200 of size 3072 next 292\n",
      "2023-05-15 17:36:29.946358: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b49e00 of size 3072 next 298\n",
      "2023-05-15 17:36:29.946360: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b4aa00 of size 3072 next 301\n",
      "2023-05-15 17:36:29.946362: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b4b600 of size 3072 next 304\n",
      "2023-05-15 17:36:29.946364: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b4c200 of size 3072 next 303\n",
      "2023-05-15 17:36:29.946366: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b4ce00 of size 3072 next 307\n",
      "2023-05-15 17:36:29.946368: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b4da00 of size 3072 next 271\n",
      "2023-05-15 17:36:29.946370: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b4e600 of size 3072 next 268\n",
      "2023-05-15 17:36:29.946372: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b4f200 of size 3072 next 269\n",
      "2023-05-15 17:36:29.946374: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b4fe00 of size 3072 next 280\n",
      "2023-05-15 17:36:29.946376: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b50a00 of size 3072 next 286\n",
      "2023-05-15 17:36:29.946378: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b51600 of size 3072 next 294\n",
      "2023-05-15 17:36:29.946380: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b52200 of size 3072 next 289\n",
      "2023-05-15 17:36:29.946383: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b52e00 of size 3072 next 348\n",
      "2023-05-15 17:36:29.946385: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b53a00 of size 3072 next 403\n",
      "2023-05-15 17:36:29.946387: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b54600 of size 3072 next 411\n",
      "2023-05-15 17:36:29.946389: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b55200 of size 3072 next 431\n",
      "2023-05-15 17:36:29.946391: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b55e00 of size 12288 next 368\n",
      "2023-05-15 17:36:29.946393: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b58e00 of size 12288 next 384\n",
      "2023-05-15 17:36:29.946397: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b5be00 of size 3072 next 386\n",
      "2023-05-15 17:36:29.946399: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b5ca00 of size 3072 next 388\n",
      "2023-05-15 17:36:29.946401: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b5d600 of size 3072 next 391\n",
      "2023-05-15 17:36:29.946403: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b5e200 of size 3072 next 392\n",
      "2023-05-15 17:36:29.946405: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b5ee00 of size 3072 next 378\n",
      "2023-05-15 17:36:29.946407: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b5fa00 of size 3072 next 381\n",
      "2023-05-15 17:36:29.946409: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b60600 of size 3072 next 394\n",
      "2023-05-15 17:36:29.946411: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b61200 of size 3072 next 397\n",
      "2023-05-15 17:36:29.946416: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b61e00 of size 12288 next 382\n",
      "2023-05-15 17:36:29.946418: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b64e00 of size 3072 next 396\n",
      "2023-05-15 17:36:29.946420: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b65a00 of size 3072 next 404\n",
      "2023-05-15 17:36:29.946422: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b66600 of size 3072 next 406\n",
      "2023-05-15 17:36:29.946424: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b67200 of size 3072 next 407\n",
      "2023-05-15 17:36:29.946426: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b67e00 of size 3072 next 414\n",
      "2023-05-15 17:36:29.946428: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b68a00 of size 12288 next 417\n",
      "2023-05-15 17:36:29.946430: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b6ba00 of size 3072 next 412\n",
      "2023-05-15 17:36:29.946432: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b6c600 of size 3072 next 419\n",
      "2023-05-15 17:36:29.946435: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b6d200 of size 3072 next 421\n",
      "2023-05-15 17:36:29.946437: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b6de00 of size 3072 next 387\n",
      "2023-05-15 17:36:29.946439: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b6ea00 of size 3072 next 409\n",
      "2023-05-15 17:36:29.946441: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b6f600 of size 3072 next 416\n",
      "2023-05-15 17:36:29.946443: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b70200 of size 3072 next 426\n",
      "2023-05-15 17:36:29.946445: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b70e00 of size 3072 next 427\n",
      "2023-05-15 17:36:29.946447: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b71a00 of size 3072 next 430\n",
      "2023-05-15 17:36:29.946449: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b72600 of size 12288 next 415\n",
      "2023-05-15 17:36:29.946451: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b75600 of size 9472 next 238\n",
      "2023-05-15 17:36:29.946454: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b77b00 of size 15104 next 248\n",
      "2023-05-15 17:36:29.946456: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b7b600 of size 12288 next 223\n",
      "2023-05-15 17:36:29.946458: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b7e600 of size 3072 next 311\n",
      "2023-05-15 17:36:29.946460: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b7f200 of size 3072 next 312\n",
      "2023-05-15 17:36:29.946462: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b7fe00 of size 3072 next 299\n",
      "2023-05-15 17:36:29.946464: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b80a00 of size 3072 next 308\n",
      "2023-05-15 17:36:29.946467: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b81600 of size 3072 next 314\n",
      "2023-05-15 17:36:29.946469: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b82200 of size 3072 next 318\n",
      "2023-05-15 17:36:29.946471: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b82e00 of size 12288 next 316\n",
      "2023-05-15 17:36:29.946473: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b85e00 of size 3072 next 315\n",
      "2023-05-15 17:36:29.946475: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b86a00 of size 3072 next 293\n",
      "2023-05-15 17:36:29.946477: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b87600 of size 3072 next 326\n",
      "2023-05-15 17:36:29.946479: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b88200 of size 3072 next 328\n",
      "2023-05-15 17:36:29.946481: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b88e00 of size 12288 next 309\n",
      "2023-05-15 17:36:29.946483: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b8be00 of size 3072 next 359\n",
      "2023-05-15 17:36:29.946485: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b8ca00 of size 3072 next 317\n",
      "2023-05-15 17:36:29.946488: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b8d600 of size 3072 next 346\n",
      "2023-05-15 17:36:29.946491: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b8e200 of size 3072 next 329\n",
      "2023-05-15 17:36:29.946493: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b8ee00 of size 3072 next 349\n",
      "2023-05-15 17:36:29.946495: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b8fa00 of size 3072 next 364\n",
      "2023-05-15 17:36:29.946497: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b90600 of size 3072 next 360\n",
      "2023-05-15 17:36:29.946499: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b91200 of size 3072 next 295\n",
      "2023-05-15 17:36:29.946501: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b91e00 of size 3072 next 296\n",
      "2023-05-15 17:36:29.946503: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b92a00 of size 3072 next 324\n",
      "2023-05-15 17:36:29.946505: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b93600 of size 3072 next 320\n",
      "2023-05-15 17:36:29.946507: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b94200 of size 3072 next 332\n",
      "2023-05-15 17:36:29.946509: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b94e00 of size 3072 next 335\n",
      "2023-05-15 17:36:29.946511: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b95a00 of size 3072 next 334\n",
      "2023-05-15 17:36:29.946513: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b96600 of size 3072 next 333\n",
      "2023-05-15 17:36:29.946515: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b97200 of size 3072 next 339\n",
      "2023-05-15 17:36:29.946517: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b97e00 of size 3072 next 343\n",
      "2023-05-15 17:36:29.946521: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b98a00 of size 3072 next 344\n",
      "2023-05-15 17:36:29.946523: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b99600 of size 3072 next 345\n",
      "2023-05-15 17:36:29.946525: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b9a200 of size 3072 next 341\n",
      "2023-05-15 17:36:29.946527: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b9ae00 of size 3072 next 325\n",
      "2023-05-15 17:36:29.946529: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b9ba00 of size 3072 next 351\n",
      "2023-05-15 17:36:29.946531: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532b9c600 of size 15360 next 350\n",
      "2023-05-15 17:36:29.946534: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532ba0200 of size 3072 next 352\n",
      "2023-05-15 17:36:29.946541: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532ba0e00 of size 3072 next 355\n",
      "2023-05-15 17:36:29.946543: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532ba1a00 of size 3072 next 358\n",
      "2023-05-15 17:36:29.946546: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532ba2600 of size 256 next 452\n",
      "2023-05-15 17:36:29.946548: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532ba2700 of size 724736 next 401\n",
      "2023-05-15 17:36:29.946550: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c53600 of size 3072 next 405\n",
      "2023-05-15 17:36:29.946552: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c54200 of size 3072 next 428\n",
      "2023-05-15 17:36:29.946555: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c54e00 of size 3072 next 435\n",
      "2023-05-15 17:36:29.946557: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c55a00 of size 3072 next 438\n",
      "2023-05-15 17:36:29.946559: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c56600 of size 12288 next 439\n",
      "2023-05-15 17:36:29.946561: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c59600 of size 3072 next 253\n",
      "2023-05-15 17:36:29.946563: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5a200 of size 3072 next 257\n",
      "2023-05-15 17:36:29.946565: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5ae00 of size 3072 next 425\n",
      "2023-05-15 17:36:29.946567: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5ba00 of size 256 next 371\n",
      "2023-05-15 17:36:29.946569: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5bb00 of size 256 next 249\n",
      "2023-05-15 17:36:29.946571: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5bc00 of size 256 next 444\n",
      "2023-05-15 17:36:29.946573: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5bd00 of size 256 next 445\n",
      "2023-05-15 17:36:29.946576: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5be00 of size 256 next 39\n",
      "2023-05-15 17:36:29.946578: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5bf00 of size 256 next 242\n",
      "2023-05-15 17:36:29.946580: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5c000 of size 256 next 443\n",
      "2023-05-15 17:36:29.946586: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5c100 of size 256 next 446\n",
      "2023-05-15 17:36:29.946588: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5c200 of size 256 next 447\n",
      "2023-05-15 17:36:29.946590: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5c300 of size 256 next 448\n",
      "2023-05-15 17:36:29.946592: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5c400 of size 256 next 449\n",
      "2023-05-15 17:36:29.946594: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5c500 of size 256 next 436\n",
      "2023-05-15 17:36:29.946597: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5c600 of size 6144 next 441\n",
      "2023-05-15 17:36:29.946599: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c5de00 of size 18432 next 354\n",
      "2023-05-15 17:36:29.946601: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c62600 of size 3072 next 374\n",
      "2023-05-15 17:36:29.946603: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c63200 of size 3072 next 375\n",
      "2023-05-15 17:36:29.946605: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c63e00 of size 3072 next 367\n",
      "2023-05-15 17:36:29.946607: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c64a00 of size 3072 next 373\n",
      "2023-05-15 17:36:29.946609: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c65600 of size 3072 next 376\n",
      "2023-05-15 17:36:29.946612: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c66200 of size 3072 next 369\n",
      "2023-05-15 17:36:29.946614: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c66e00 of size 3072 next 383\n",
      "2023-05-15 17:36:29.946616: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c67a00 of size 3072 next 380\n",
      "2023-05-15 17:36:29.946618: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c68600 of size 3072 next 398\n",
      "2023-05-15 17:36:29.946620: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532c69200 of size 2359296 next 262\n",
      "2023-05-15 17:36:29.946622: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 532ea9200 of size 3545088 next 234\n",
      "2023-05-15 17:36:29.946625: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53320aa00 of size 7108608 next 38\n",
      "2023-05-15 17:36:29.946627: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5338d2200 of size 2359296 next 244\n",
      "2023-05-15 17:36:29.946629: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 533b12200 of size 2359296 next 261\n",
      "2023-05-15 17:36:29.946631: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 533d52200 of size 2359296 next 266\n",
      "2023-05-15 17:36:29.946633: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 533f92200 of size 2359296 next 270\n",
      "2023-05-15 17:36:29.946635: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5341d2200 of size 2359296 next 264\n",
      "2023-05-15 17:36:29.946637: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 534412200 of size 2359296 next 278\n",
      "2023-05-15 17:36:29.946639: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 534652200 of size 2359296 next 284\n",
      "2023-05-15 17:36:29.946642: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 534892200 of size 2359296 next 256\n",
      "2023-05-15 17:36:29.946645: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 534ad2200 of size 13486080 next 226\n",
      "2023-05-15 17:36:29.946647: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 5357aea00 of size 93763584 next 229\n",
      "2023-05-15 17:36:29.946650: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53b11a200 of size 9437184 next 259\n",
      "2023-05-15 17:36:29.946652: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53ba1a200 of size 2359296 next 281\n",
      "2023-05-15 17:36:29.946654: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53bc5a200 of size 2359296 next 297\n",
      "2023-05-15 17:36:29.946656: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53be9a200 of size 2359296 next 300\n",
      "2023-05-15 17:36:29.946658: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53c0da200 of size 2359296 next 272\n",
      "2023-05-15 17:36:29.946660: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53c31a200 of size 9437184 next 273\n",
      "2023-05-15 17:36:29.946663: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53cc1a200 of size 9437184 next 246\n",
      "2023-05-15 17:36:29.946665: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53d51a200 of size 2359296 next 283\n",
      "2023-05-15 17:36:29.946667: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53d75a200 of size 2359296 next 274\n",
      "2023-05-15 17:36:29.946669: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53d99a200 of size 2359296 next 310\n",
      "2023-05-15 17:36:29.946671: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53dbda200 of size 2359296 next 290\n",
      "2023-05-15 17:36:29.946673: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53de1a200 of size 9437184 next 291\n",
      "2023-05-15 17:36:29.946676: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53e71a200 of size 9437184 next 277\n",
      "2023-05-15 17:36:29.946678: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53f01a200 of size 2359296 next 393\n",
      "2023-05-15 17:36:29.946680: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53f25a200 of size 2359296 next 399\n",
      "2023-05-15 17:36:29.946683: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 53f49a200 of size 2359296 next 410\n",
      "2023-05-15 17:36:29.946685: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 53f6da200 of size 133263360 next 400\n",
      "2023-05-15 17:36:29.946687: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5475f1200 of size 9437184 next 395\n",
      "2023-05-15 17:36:29.946689: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 547ef1200 of size 9437184 next 402\n",
      "2023-05-15 17:36:29.946692: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 5487f1200 of size 2359296 next 408\n",
      "2023-05-15 17:36:29.946694: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 548a31200 of size 16515072 next 418\n",
      "2023-05-15 17:36:29.946697: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5499f1200 of size 2359296 next 424\n",
      "2023-05-15 17:36:29.946699: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 549c31200 of size 2359296 next 422\n",
      "2023-05-15 17:36:29.946701: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 549e71200 of size 2359296 next 413\n",
      "2023-05-15 17:36:29.946703: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 54a0b1200 of size 2359296 next 420\n",
      "2023-05-15 17:36:29.946706: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 54a2f1200 of size 9437184 next 432\n",
      "2023-05-15 17:36:29.946708: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 54abf1200 of size 9437184 next 433\n",
      "2023-05-15 17:36:29.946710: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 54b4f1200 of size 9437184 next 434\n",
      "2023-05-15 17:36:29.946713: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 54bdf1200 of size 9437184 next 302\n",
      "2023-05-15 17:36:29.946715: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 54c6f1200 of size 9437184 next 17\n",
      "2023-05-15 17:36:29.946717: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 54cff1200 of size 9437184 next 423\n",
      "2023-05-15 17:36:29.946719: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 54d8f1200 of size 7108608 next 306\n",
      "2023-05-15 17:36:29.946721: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 54dfb8a00 of size 7108608 next 239\n",
      "2023-05-15 17:36:29.946724: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 54e680200 of size 51234816 next 429\n",
      "2023-05-15 17:36:29.946726: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 55175ca00 of size 93763584 next 440\n",
      "2023-05-15 17:36:29.946730: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5570c8200 of size 355540992 next 32\n",
      "2023-05-15 17:36:29.946736: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 56c3da200 of size 355540992 next 33\n",
      "2023-05-15 17:36:29.946739: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5816ec200 of size 355540992 next 70\n",
      "2023-05-15 17:36:29.946742: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 5969fe200 of size 355540992 next 59\n",
      "2023-05-15 17:36:29.946744: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 5abd10200 of size 355540992 next 53\n",
      "2023-05-15 17:36:29.946746: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 5c1022200 of size 642637312 next 18446744073709551615\n",
      "2023-05-15 17:36:29.946749: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
      "2023-05-15 17:36:29.946752: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 56 Chunks of size 256 totalling 14.0KiB\n",
      "2023-05-15 17:36:29.946755: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-05-15 17:36:29.946758: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 110 Chunks of size 3072 totalling 330.0KiB\n",
      "2023-05-15 17:36:29.946760: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 5888 totalling 5.8KiB\n",
      "2023-05-15 17:36:29.946762: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 6144 totalling 6.0KiB\n",
      "2023-05-15 17:36:29.946768: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 3 Chunks of size 9472 totalling 27.8KiB\n",
      "2023-05-15 17:36:29.946770: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 11 Chunks of size 12288 totalling 132.0KiB\n",
      "2023-05-15 17:36:29.946788: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 15104 totalling 14.8KiB\n",
      "2023-05-15 17:36:29.946791: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 15360 totalling 15.0KiB\n",
      "2023-05-15 17:36:29.946793: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 18432 totalling 18.0KiB\n",
      "2023-05-15 17:36:29.946796: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 724736 totalling 707.8KiB\n",
      "2023-05-15 17:36:29.946798: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 49 Chunks of size 2359296 totalling 110.25MiB\n",
      "2023-05-15 17:36:29.946801: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3545088 totalling 3.38MiB\n",
      "2023-05-15 17:36:29.946803: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 7108608 totalling 27.12MiB\n",
      "2023-05-15 17:36:29.946806: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 22 Chunks of size 9437184 totalling 198.00MiB\n",
      "2023-05-15 17:36:29.946809: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 13486080 totalling 12.86MiB\n",
      "2023-05-15 17:36:29.946811: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 16515072 totalling 15.75MiB\n",
      "2023-05-15 17:36:29.946828: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 17031168 totalling 16.24MiB\n",
      "2023-05-15 17:36:29.946832: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 93763584 totalling 89.42MiB\n",
      "2023-05-15 17:36:29.946835: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 355540992 totalling 1.32GiB\n",
      "2023-05-15 17:36:29.946838: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 1.79GiB\n",
      "2023-05-15 17:36:29.946842: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 3547332608 memory_limit_: 3547332608 available bytes: 0 curr_region_allocation_bytes_: 7094665216\n",
      "2023-05-15 17:36:29.946849: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
      "Limit:                      3547332608\n",
      "InUse:                      1919465728\n",
      "MaxInUse:                   2413532416\n",
      "NumAllocs:                        4100\n",
      "MaxAllocSize:               1422163968\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-05-15 17:36:29.946869: W tensorflow/tsl/framework/bfc_allocator.cc:497] *___*****___****__***___****_*********************************_________***********__________________\n",
      "2023-05-15 17:36:29.946912: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at matmul_op_impl.h:730 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[8,12,14467,14467] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "2023-05-15 17:36:29.946968: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[8,12,14467,14467] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n",
      "\t [[{{node model_1/tf_bert_model_1/bert/encoder/layer_._0/attention/self/MatMul}}]]\n",
      "Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n",
      "\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_1/tf_bert_model_1/bert/encoder/layer_._0/attention/self/MatMul' defined at (most recent call last):\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_56327/3477426987.py\", line 7, in <module>\n      history = model.fit([train_data, train_attention_masks],\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1087, in run_call_with_unpacked_inputs\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1114, in call\n      outputs = self.bert(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1087, in run_call_with_unpacked_inputs\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 870, in call\n      encoder_outputs = self.encoder(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 556, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 562, in call\n      layer_outputs = layer_module(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 472, in call\n      self_attention_outputs = self.attention(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 388, in call\n      self_outputs = self.self_attention(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 318, in call\n      attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\nNode: 'model_1/tf_bert_model_1/bert/encoder/layer_._0/attention/self/MatMul'\nOOM when allocating tensor with shape[8,12,14467,14467] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/tf_bert_model_1/bert/encoder/layer_._0/attention/self/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_131426]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(learning_rate\u001b[39m=\u001b[39m\u001b[39m2e-5\u001b[39m),\n\u001b[1;32m      3\u001b[0m               loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m               metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit([train_data, train_attention_masks],\n\u001b[1;32m      8\u001b[0m                     train_labels,\n\u001b[1;32m      9\u001b[0m                     validation_data\u001b[39m=\u001b[39;49m([valid_data, valid_attention_masks], valid_labels),\n\u001b[1;32m     10\u001b[0m                     epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m                     batch_size\u001b[39m=\u001b[39;49m\u001b[39m8\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/nlp/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_1/tf_bert_model_1/bert/encoder/layer_._0/attention/self/MatMul' defined at (most recent call last):\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/traitlets/config/application.py\", line 1043, in launch_instance\n      app.start()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_56327/3477426987.py\", line 7, in <module>\n      history = model.fit([train_data, train_attention_masks],\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 1050, in train_step\n      y_pred = self(x, training=True)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/functional.py\", line 512, in call\n      return self._run_internal_graph(inputs, training=training, mask=mask)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/functional.py\", line 669, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/training.py\", line 558, in __call__\n      return super().__call__(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1087, in run_call_with_unpacked_inputs\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 1114, in call\n      outputs = self.bert(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/modeling_tf_utils.py\", line 1087, in run_call_with_unpacked_inputs\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 870, in call\n      encoder_outputs = self.encoder(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 556, in call\n      for i, layer_module in enumerate(self.layer):\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 562, in call\n      layer_outputs = layer_module(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 472, in call\n      self_attention_outputs = self.attention(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 388, in call\n      self_outputs = self.self_attention(\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/engine/base_layer.py\", line 1145, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 96, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zoro/miniconda3/envs/nlp/lib/python3.9/site-packages/transformers/models/bert/modeling_tf_bert.py\", line 318, in call\n      attention_scores = tf.matmul(query_layer, key_layer, transpose_b=True)\nNode: 'model_1/tf_bert_model_1/bert/encoder/layer_._0/attention/self/MatMul'\nOOM when allocating tensor with shape[8,12,14467,14467] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_1/tf_bert_model_1/bert/encoder/layer_._0/attention/self/MatMul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_131426]"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit([train_data, train_attention_masks],\n",
    "                    train_labels,\n",
    "                    validation_data=([valid_data, valid_attention_masks], valid_labels),\n",
    "                    epochs=5,\n",
    "                    batch_size=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2cbc66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
